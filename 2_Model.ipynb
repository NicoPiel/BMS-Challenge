{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afeec7c3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1f098d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:03/2021-05-02T23:55:03)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e9cfe",
   "metadata": {},
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a44e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:03/2021-05-02T23:55:03)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "PREPROCESS_DIR = 'input/inchi-preprocess'\n",
    "if not os.path.exists(PREPROCESS_DIR):\n",
    "    os.makedirs(PREPROCESS_DIR)\n",
    "    \n",
    "    \n",
    "if os.path.isfile('train.log'):\n",
    "    os.remove('train.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e67287",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2536f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 17.6 s (2021-05-02T23:55:03/2021-05-02T23:55:21)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (2424186, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChI_1</th>\n",
       "      <th>InChI_text</th>\n",
       "      <th>InChI_length</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>C13H20OS</td>\n",
       "      <td>C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...</td>\n",
       "      <td>59</td>\n",
       "      <td>input/train/0/0/0/000011a64c74.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>C21H30O4</td>\n",
       "      <td>C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...</td>\n",
       "      <td>108</td>\n",
       "      <td>input/train/0/0/0/000019cc0cd2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>C24H23N5O4</td>\n",
       "      <td>C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...</td>\n",
       "      <td>112</td>\n",
       "      <td>input/train/0/0/0/0000252b6d2b.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>C17H24N2O4S</td>\n",
       "      <td>C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...</td>\n",
       "      <td>108</td>\n",
       "      <td>input/train/0/0/0/000026b49b7e.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>C10H19N3O2S</td>\n",
       "      <td>C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...</td>\n",
       "      <td>72</td>\n",
       "      <td>input/train/0/0/0/000026fc6c36.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "       InChI_1                                         InChI_text  \\\n",
       "0     C13H20OS  C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...   \n",
       "1     C21H30O4  C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...   \n",
       "2   C24H23N5O4  C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...   \n",
       "3  C17H24N2O4S  C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...   \n",
       "4  C10H19N3O2S  C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...   \n",
       "\n",
       "   InChI_length                           file_path  \n",
       "0            59  input/train/0/0/0/000011a64c74.png  \n",
       "1           108  input/train/0/0/0/000019cc0cd2.png  \n",
       "2           112  input/train/0/0/0/0000252b6d2b.png  \n",
       "3           108  input/train/0/0/0/000026b49b7e.png  \n",
       "4            72  input/train/0/0/0/000026fc6c36.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "import torch\n",
    "\n",
    "train = pd.read_json(f'{PREPROCESS_DIR}/train.json')\n",
    "\n",
    "def get_train_file_path(image_id):\n",
    "    return \"input/train/{}/{}/{}/{}.png\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id \n",
    "    )\n",
    "\n",
    "train['file_path'] = train['image_id'].apply(get_train_file_path)\n",
    "\n",
    "print(f'train.shape: {train.shape}')\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5c7795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:21/2021-05-02T23:55:21)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.stoi: {'(': 0, ')': 1, '+': 2, ',': 3, '-': 4, '/b': 5, '/c': 6, '/h': 7, '/i': 8, '/m': 9, '/s': 10, '/t': 11, '0': 12, '1': 13, '10': 14, '100': 15, '101': 16, '102': 17, '103': 18, '104': 19, '105': 20, '106': 21, '107': 22, '108': 23, '109': 24, '11': 25, '110': 26, '111': 27, '112': 28, '113': 29, '114': 30, '115': 31, '116': 32, '117': 33, '118': 34, '119': 35, '12': 36, '120': 37, '121': 38, '122': 39, '123': 40, '124': 41, '125': 42, '126': 43, '127': 44, '128': 45, '129': 46, '13': 47, '130': 48, '131': 49, '132': 50, '133': 51, '134': 52, '135': 53, '136': 54, '137': 55, '138': 56, '139': 57, '14': 58, '140': 59, '141': 60, '142': 61, '143': 62, '144': 63, '145': 64, '146': 65, '147': 66, '148': 67, '149': 68, '15': 69, '150': 70, '151': 71, '152': 72, '153': 73, '154': 74, '155': 75, '156': 76, '157': 77, '158': 78, '159': 79, '16': 80, '161': 81, '163': 82, '165': 83, '167': 84, '17': 85, '18': 86, '19': 87, '2': 88, '20': 89, '21': 90, '22': 91, '23': 92, '24': 93, '25': 94, '26': 95, '27': 96, '28': 97, '29': 98, '3': 99, '30': 100, '31': 101, '32': 102, '33': 103, '34': 104, '35': 105, '36': 106, '37': 107, '38': 108, '39': 109, '4': 110, '40': 111, '41': 112, '42': 113, '43': 114, '44': 115, '45': 116, '46': 117, '47': 118, '48': 119, '49': 120, '5': 121, '50': 122, '51': 123, '52': 124, '53': 125, '54': 126, '55': 127, '56': 128, '57': 129, '58': 130, '59': 131, '6': 132, '60': 133, '61': 134, '62': 135, '63': 136, '64': 137, '65': 138, '66': 139, '67': 140, '68': 141, '69': 142, '7': 143, '70': 144, '71': 145, '72': 146, '73': 147, '74': 148, '75': 149, '76': 150, '77': 151, '78': 152, '79': 153, '8': 154, '80': 155, '81': 156, '82': 157, '83': 158, '84': 159, '85': 160, '86': 161, '87': 162, '88': 163, '89': 164, '9': 165, '90': 166, '91': 167, '92': 168, '93': 169, '94': 170, '95': 171, '96': 172, '97': 173, '98': 174, '99': 175, 'B': 176, 'Br': 177, 'C': 178, 'Cl': 179, 'D': 180, 'F': 181, 'H': 182, 'I': 183, 'N': 184, 'O': 185, 'P': 186, 'S': 187, 'Si': 188, 'T': 189, '<sos>': 190, '<eos>': 191, '<pad>': 192}\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        vocab = set()\n",
    "        for text in texts:\n",
    "            vocab.update(text.split(' '))\n",
    "        vocab = sorted(vocab)\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for i, s in enumerate(vocab):\n",
    "            self.stoi[s] = i\n",
    "        self.itos = {item[1]: item[0] for item in self.stoi.items()}\n",
    "        \n",
    "    def text_to_sequence(self, text):\n",
    "        sequence = []\n",
    "        sequence.append(self.stoi['<sos>'])\n",
    "        for s in text.split(' '):\n",
    "            sequence.append(self.stoi[s])\n",
    "        sequence.append(self.stoi['<eos>'])\n",
    "        return sequence\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = self.text_to_sequence(text)\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "\n",
    "    def sequence_to_text(self, sequence):\n",
    "        return ''.join(list(map(lambda i: self.itos[i], sequence)))\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = self.sequence_to_text(sequence)\n",
    "            texts.append(text)\n",
    "        return texts\n",
    "    \n",
    "    def predict_caption(self, sequence):\n",
    "        caption = ''\n",
    "        for i in sequence:\n",
    "            if i == self.stoi['<eos>'] or i == self.stoi['<pad>']:\n",
    "                break\n",
    "            caption += self.itos[i]\n",
    "        return caption\n",
    "    \n",
    "    def predict_captions(self, sequences):\n",
    "        captions = []\n",
    "        for sequence in sequences:\n",
    "            caption = self.predict_caption(sequence)\n",
    "            captions.append(caption)\n",
    "        return captions\n",
    "\n",
    "tokenizer = torch.load(f'{PREPROCESS_DIR}/tokenizer.pth', pickle_module=dill)\n",
    "print(f\"tokenizer.stoi: {tokenizer.stoi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2252c1e",
   "metadata": {},
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69701539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 16 ms (2021-05-02T23:55:21/2021-05-02T23:55:21)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 workers.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    max_len=275\n",
    "    print_freq=1000\n",
    "    num_workers=16 if os.cpu_count() >= 16 else os.cpu_count()\n",
    "    model_name='resnet34'\n",
    "    size=224\n",
    "    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    epochs=1 # not to exceed 9h\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=4 # CosineAnnealingLR\n",
    "    #T_0=4 # CosineAnnealingWarmRestarts\n",
    "    encoder_lr=1e-4\n",
    "    decoder_lr=4e-4\n",
    "    min_lr=1e-6\n",
    "    batch_size=64\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=5\n",
    "    attention_dim=256\n",
    "    embed_dim=256\n",
    "    decoder_dim=512\n",
    "    dropout=0.5\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0] # [0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    \n",
    "print(f'Using {CFG.num_workers} workers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db4ee0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:21/2021-05-02T23:55:21)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    train = train[:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69494a39",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eff7bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 1.52 s (2021-05-02T23:55:22/2021-05-02T23:55:23)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of available devices: 1\n",
      "Device names: \n",
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "sys.path.append('input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import Levenshtein\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, Blur\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda' if cuda_available else 'cpu')\n",
    "\n",
    "if (cuda_available):\n",
    "    torch.cuda.init()\n",
    "    print(f'CUDA available: {cuda_available}')\n",
    "    print(f'Number of available devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device names: ')\n",
    "\n",
    "    for i in np.arange(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd82aa6",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7bd16b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:24/2021-05-02T23:55:24)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        score = Levenshtein.distance(true, pred)\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8254dc66",
   "metadata": {},
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e049db87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 63 ms (2021-05-02T23:55:24/2021-05-02T23:55:24)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    20000\n",
      "1    20000\n",
      "2    20000\n",
      "3    20000\n",
      "4    20000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['InChI_length'])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a8006",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e749277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:24/2021-05-02T23:55:24)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.file_paths = df['file_path'].values\n",
    "        self.labels = df['InChI_text'].values\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = self.labels[idx]\n",
    "        label = self.tokenizer.text_to_sequence(label)\n",
    "        label_length = len(label)\n",
    "        label_length = torch.LongTensor([label_length])\n",
    "        return image, torch.LongTensor(label), label_length\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.file_paths = df['file_path'].values\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6059328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:24/2021-05-02T23:55:24)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bms_collate(batch):\n",
    "    imgs, labels, label_lengths = [], [], []\n",
    "    for data_point in batch:\n",
    "        imgs.append(data_point[0])\n",
    "        labels.append(data_point[1])\n",
    "        label_lengths.append(data_point[2])\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.stoi[\"<pad>\"])\n",
    "    return torch.stack(imgs), labels, torch.stack(label_lengths).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aacb55c",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d064f9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:25/2021-05-02T23:55:25)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3befa1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 359 ms (2021-05-02T23:55:25/2021-05-02T23:55:25)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_dataset = TrainDataset(train, tokenizer, transform=get_transforms(data='train'))\n",
    "\n",
    "for i in range(1):\n",
    "    image, label, label_length = train_dataset[i]\n",
    "    text = tokenizer.sequence_to_text(label.numpy())\n",
    "    plt.imshow(image.transpose(0, 1).transpose(1, 2))\n",
    "    plt.title(f'label: {label}  text: {text}  label_length: {label_length}')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfb632",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7e9d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:25/2021-05-02T23:55:25)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, model_name='resnet18', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.n_features = self.cnn.fc.in_features\n",
    "        self.cnn.global_pool = nn.Identity()\n",
    "        self.cnn.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.cnn(x)\n",
    "        features = features.permute(0, 2, 3, 1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f95d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:25/2021-05-02T23:55:25)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention network for calculate attention value\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
    "        \"\"\"\n",
    "        :param encoder_dim: input size of encoder network\n",
    "        :param decoder_dim: input size of decoder network\n",
    "        :param attention_dim: input size of attention network\n",
    "        \"\"\"\n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)  # linear layer to transform encoded image\n",
    "        self.decoder_att = nn.Linear(decoder_dim, attention_dim)  # linear layer to transform decoder's output\n",
    "        self.full_att = nn.Linear(attention_dim, 1)  # linear layer to calculate values to be softmax-ed\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)  # softmax layer to calculate weights\n",
    "\n",
    "    def forward(self, encoder_out, decoder_hidden):\n",
    "        att1 = self.encoder_att(encoder_out)  # (batch_size, num_pixels, attention_dim)\n",
    "        att2 = self.decoder_att(decoder_hidden)  # (batch_size, attention_dim)\n",
    "        att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2)  # (batch_size, num_pixels)\n",
    "        alpha = self.softmax(att)  # (batch_size, num_pixels)\n",
    "        attention_weighted_encoding = (encoder_out * alpha.unsqueeze(2)).sum(dim=1)  # (batch_size, encoder_dim)\n",
    "        return attention_weighted_encoding, alpha\n",
    "\n",
    "\n",
    "class DecoderWithAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder network with attention network used for training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, device, encoder_dim=512, dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param attention_dim: input size of attention network\n",
    "        :param embed_dim: input size of embedding network\n",
    "        :param decoder_dim: input size of decoder network\n",
    "        :param vocab_size: total number of characters used in training\n",
    "        :param encoder_dim: input size of encoder network\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super(DecoderWithAttention, self).__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        self.attention = Attention(encoder_dim, decoder_dim, attention_dim)  # attention network\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)  # embedding layer\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.decode_step = nn.LSTMCell(embed_dim + encoder_dim, decoder_dim, bias=True)  # decoding LSTMCell\n",
    "        self.init_h = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial hidden state of LSTMCell\n",
    "        self.init_c = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial cell state of LSTMCell\n",
    "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)  # linear layer to create a sigmoid-activated gate\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc = nn.Linear(decoder_dim, vocab_size)  # linear layer to find scores over vocabulary\n",
    "        self.init_weights()  # initialize some layers with the uniform distribution\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "\n",
    "    def fine_tune_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "\n",
    "    def init_hidden_state(self, encoder_out):\n",
    "        mean_encoder_out = encoder_out.mean(dim=1)\n",
    "        h = self.init_h(mean_encoder_out)  # (batch_size, decoder_dim)\n",
    "        c = self.init_c(mean_encoder_out)\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths):\n",
    "        \"\"\"\n",
    "        :param encoder_out: output of encoder network\n",
    "        :param encoded_captions: transformed sequence from character to integer\n",
    "        :param caption_lengths: length of transformed sequence\n",
    "        \"\"\"\n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        num_pixels = encoder_out.size(1)\n",
    "        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim=0, descending=True)\n",
    "        encoder_out = encoder_out[sort_ind]\n",
    "        encoded_captions = encoded_captions[sort_ind]\n",
    "        # embedding transformed sequence for vector\n",
    "        embeddings = self.embedding(encoded_captions)  # (batch_size, max_caption_length, embed_dim)\n",
    "        # initialize hidden state and cell state of LSTM cell\n",
    "        h, c = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
    "        # set decode length by caption length - 1 because of omitting start token\n",
    "        decode_lengths = (caption_lengths - 1).tolist()\n",
    "        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(self.device)\n",
    "        alphas = torch.zeros(batch_size, max(decode_lengths), num_pixels).to(self.device)\n",
    "        # predict sequence\n",
    "        for t in range(max(decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in decode_lengths])\n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t], h[:batch_size_t])\n",
    "            gate = self.sigmoid(self.f_beta(h[:batch_size_t]))  # gating scalar, (batch_size_t, encoder_dim)\n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "            h, c = self.decode_step(\n",
    "                torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1),\n",
    "                (h[:batch_size_t], c[:batch_size_t]))  # (batch_size_t, decoder_dim)\n",
    "            preds = self.fc(self.dropout(h))  # (batch_size_t, vocab_size)\n",
    "            predictions[:batch_size_t, t, :] = preds\n",
    "            alphas[:batch_size_t, t, :] = alpha\n",
    "        return predictions, encoded_captions, decode_lengths, alphas, sort_ind\n",
    "    \n",
    "    def predict(self, encoder_out, decode_lengths, tokenizer):\n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        num_pixels = encoder_out.size(1)\n",
    "        # embed start tocken for LSTM input\n",
    "        start_tockens = torch.ones(batch_size, dtype=torch.long).to(self.device) * tokenizer.stoi[\"<sos>\"]\n",
    "        embeddings = self.embedding(start_tockens)\n",
    "        # initialize hidden state and cell state of LSTM cell\n",
    "        h, c = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
    "        predictions = torch.zeros(batch_size, decode_lengths, vocab_size).to(self.device)\n",
    "        # predict sequence\n",
    "        for t in range(decode_lengths):\n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out, h)\n",
    "            gate = self.sigmoid(self.f_beta(h))  # gating scalar, (batch_size_t, encoder_dim)\n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "            h, c = self.decode_step(\n",
    "                torch.cat([embeddings, attention_weighted_encoding], dim=1),\n",
    "                (h, c))  # (batch_size_t, decoder_dim)\n",
    "            preds = self.fc(self.dropout(h))  # (batch_size_t, vocab_size)\n",
    "            predictions[:, t, :] = preds\n",
    "            if np.argmax(preds.detach().cpu().numpy()) == tokenizer.stoi[\"<eos>\"]:\n",
    "                break\n",
    "            embeddings = self.embedding(torch.argmax(preds, -1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e71287",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c7a8072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:26/2021-05-02T23:55:26)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, encoder, decoder, criterion, \n",
    "             encoder_optimizer, decoder_optimizer, epoch,\n",
    "             encoder_scheduler, decoder_scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    # switch to train mode\n",
    "    LOGGER.info('Switching to train mode ..')\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    LOGGER.info('Enumerating train loader ..')\n",
    "    for step, (images, labels, label_lengths) in enumerate(train_loader):\n",
    "        LOGGER.info(f'Step: {step}')\n",
    "        LOGGER.info('Training - Measuring data loading time ..')\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        LOGGER.info('Training - loading data ..')\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        LOGGER.info('Training - encoding ..')\n",
    "        features = encoder(images)\n",
    "        LOGGER.info('Training - decoding ..')\n",
    "        predictions, caps_sorted, decode_lengths, alphas, sort_ind = decoder(features, labels, label_lengths)\n",
    "        targets = caps_sorted[:, 1:]\n",
    "        predictions = pack_padded_sequence(predictions, decode_lengths, batch_first=True).data\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "        loss = criterion(predictions, targets)\n",
    "        # record loss\n",
    "        LOGGER.info('Training - recording ..')\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        encoder_grad_norm = torch.nn.utils.clip_grad_norm_(encoder.parameters(), CFG.max_grad_norm)\n",
    "        decoder_grad_norm = torch.nn.utils.clip_grad_norm_(decoder.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Encoder Grad: {encoder_grad_norm:.4f}  '\n",
    "                  'Decoder Grad: {decoder_grad_norm:.4f}  '\n",
    "                  #'Encoder LR: {encoder_lr:.6f}  '\n",
    "                  #'Decoder LR: {decoder_lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   encoder_grad_norm=encoder_grad_norm,\n",
    "                   decoder_grad_norm=decoder_grad_norm,\n",
    "                   #encoder_lr=encoder_scheduler.get_lr()[0],\n",
    "                   #decoder_lr=decoder_scheduler.get_lr()[0],\n",
    "                   ))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, encoder, decoder, tokenizer, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    LOGGER.info('Switching to evaluation mode ..')\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    text_preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images) in enumerate(valid_loader):\n",
    "        LOGGER.info(f'Step: {step}')\n",
    "        # measure data loading time\n",
    "        LOGGER.info('Evaluation - loading data ..')\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            LOGGER.info('Evaluation - encoding ..')\n",
    "            features = encoder(images)\n",
    "            LOGGER.info('Evaluation - decoding ..')\n",
    "            predictions = decoder.predict(features, CFG.max_len, tokenizer)\n",
    "        predicted_sequence = torch.argmax(predictions.detach().cpu(), -1).numpy()\n",
    "        _text_preds = tokenizer.predict_captions(predicted_sequence)\n",
    "        text_preds.append(_text_preds)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  .format(\n",
    "                   step, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "    text_preds = np.concatenate(text_preds)\n",
    "    return text_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa957f",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42b83f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 16 ms (2021-05-02T23:55:26/2021-05-02T23:55:26)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    \n",
    "    LOGGER.info('Loading ..')\n",
    "    \n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    valid_labels = valid_folds['InChI'].values\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, tokenizer, transform=get_transforms(data='train'))\n",
    "    valid_dataset = TestDataset(valid_folds, transform=get_transforms(data='valid'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=CFG.num_workers, \n",
    "                              pin_memory=True,\n",
    "                              drop_last=True, \n",
    "                              collate_fn=bms_collate)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers,\n",
    "                              pin_memory=True, \n",
    "                              drop_last=False)\n",
    "    \n",
    "    display(valid_folds)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    \n",
    "    LOGGER.info('Creating encoder ..')\n",
    "    \n",
    "    encoder = Encoder(CFG.model_name, pretrained=True)\n",
    "    encoder.to(device)\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr=CFG.encoder_lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    encoder_scheduler = get_scheduler(encoder_optimizer)\n",
    "    \n",
    "    LOGGER.info('Creating decoder ..')\n",
    "    \n",
    "    decoder = DecoderWithAttention(attention_dim=CFG.attention_dim,\n",
    "                                   embed_dim=CFG.embed_dim,\n",
    "                                   decoder_dim=CFG.decoder_dim,\n",
    "                                   vocab_size=len(tokenizer),\n",
    "                                   dropout=CFG.dropout,\n",
    "                                   device=device)\n",
    "    decoder.to(device)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr=CFG.decoder_lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    decoder_scheduler = get_scheduler(decoder_optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.stoi[\"<pad>\"])\n",
    "\n",
    "    best_score = np.inf\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    LOGGER.info('Starting loop ..')\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        LOGGER.info(f'Epoch: {epoch}')\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        LOGGER.info('Starting training ..')\n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, encoder, decoder, criterion, \n",
    "                            encoder_optimizer, decoder_optimizer, epoch, \n",
    "                            encoder_scheduler, decoder_scheduler, device)\n",
    "\n",
    "        LOGGER.info('Evaluating ..')\n",
    "        \n",
    "        # eval\n",
    "        text_preds = valid_fn(valid_loader, encoder, decoder, tokenizer, criterion, device)\n",
    "        text_preds = [f\"InChI=1S/{text}\" for text in text_preds]\n",
    "        LOGGER.info(f\"labels: {valid_labels[:5]}\")\n",
    "        LOGGER.info(f\"preds: {text_preds[:5]}\")\n",
    "        \n",
    "        LOGGER.info('Scoring ..')\n",
    "        \n",
    "        # scoring\n",
    "        score, scores = get_score(valid_labels, text_preds)\n",
    "        LOGGER.info(f'Average levenshtein distance: {score}')\n",
    "        \n",
    "        image_keys = pd.read_csv('train_labels.csv')\n",
    "        \n",
    "        LOGGER.info('Writing output csv')\n",
    "        \n",
    "        LOGGER.info(f'Num scores: {len(scores)}')\n",
    "        LOGGER.info(f'Num preds: {len(text_preds)}')\n",
    "        \n",
    "        scores_computed = pd.DataFrame({\n",
    "            'predicted_inchi': text_preds,\n",
    "            'score': scores\n",
    "        })\n",
    "        \n",
    "        LOGGER.info(f\"Num image ids: {len(valid_folds['image_id'])}\")\n",
    "        LOGGER.info(f\"Num actual inchis: {len(valid_folds['InChI'])}\")\n",
    "        \n",
    "        scores_actual = pd.DataFrame({\n",
    "            'image_id': valid_folds['image_id'],\n",
    "            'actual_inchi': valid_folds['InChI']\n",
    "        })\n",
    "        \n",
    "        scores_out = pd.concat([scores_actual, scores_computed], axis=1)\n",
    "        \n",
    "        scores_out.sort_values('score', ascending=False).to_csv('output.csv', index=False)\n",
    "        \n",
    "        \n",
    "        if isinstance(encoder_scheduler, ReduceLROnPlateau):\n",
    "            encoder_scheduler.step(score)\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingLR):\n",
    "            encoder_scheduler.step()\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            encoder_scheduler.step()\n",
    "            \n",
    "        if isinstance(decoder_scheduler, ReduceLROnPlateau):\n",
    "            decoder_scheduler.step(score)\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingLR):\n",
    "            decoder_scheduler.step()\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            decoder_scheduler.step()\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'encoder': encoder.state_dict(), \n",
    "                        'encoder_optimizer': encoder_optimizer.state_dict(), \n",
    "                        'encoder_scheduler': encoder_scheduler.state_dict(), \n",
    "                        'decoder': decoder.state_dict(), \n",
    "                        'decoder_optimizer': decoder_optimizer.state_dict(), \n",
    "                        'decoder_scheduler': decoder_scheduler.state_dict(), \n",
    "                        'text_preds': text_preds,\n",
    "                       },\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9dda37",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1711696c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 0 ns (2021-05-02T23:55:26/2021-05-02T23:55:26)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare: 1.train  2.folds\n",
    "    \"\"\"\n",
    "\n",
    "    if CFG.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                train_loop(folds, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffe67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>⌛ 42.6 s (2021-05-02T23:55:27)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Loading ..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChI_1</th>\n",
       "      <th>InChI_text</th>\n",
       "      <th>InChI_length</th>\n",
       "      <th>file_path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>C10H19N3O2S</td>\n",
       "      <td>C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...</td>\n",
       "      <td>72</td>\n",
       "      <td>input/train/0/0/0/000026fc6c36.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000045d5fbf9</td>\n",
       "      <td>InChI=1S/C13H15BrN2O3/c1-7-5-15-6-9(7)12(17)16...</td>\n",
       "      <td>C13H15BrN2O3</td>\n",
       "      <td>C 13 H 15 Br N 2 O 3 /c 1 - 7 - 5 - 15 - 6 - 9...</td>\n",
       "      <td>97</td>\n",
       "      <td>input/train/0/0/0/000045d5fbf9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000642345c8</td>\n",
       "      <td>InChI=1S/C16H12O7/c1-22-14-5-9(18)8(4-10(14)19...</td>\n",
       "      <td>C16H12O7</td>\n",
       "      <td>C 16 H 12 O 7 /c 1 - 22 - 14 - 5 - 9 ( 18 ) 8 ...</td>\n",
       "      <td>84</td>\n",
       "      <td>input/train/0/0/0/0000642345c8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000092011e0d</td>\n",
       "      <td>InChI=1S/C13H14O2/c14-12-8-9-13(15)11(12)7-6-1...</td>\n",
       "      <td>C13H14O2</td>\n",
       "      <td>C 13 H 14 O 2 /c 14 - 12 - 8 - 9 - 13 ( 15 ) 1...</td>\n",
       "      <td>53</td>\n",
       "      <td>input/train/0/0/0/000092011e0d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000960e9456</td>\n",
       "      <td>InChI=1S/C9H7BrClN3S/c10-7-3-1-6(2-4-7)5-12-9-...</td>\n",
       "      <td>C9H7BrClN3S</td>\n",
       "      <td>C 9 H 7 Br Cl N 3 S /c 10 - 7 - 3 - 1 - 6 ( 2 ...</td>\n",
       "      <td>60</td>\n",
       "      <td>input/train/0/0/0/0000960e9456.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0a8f483e026a</td>\n",
       "      <td>InChI=1S/C25H17F2N3O5/c1-11-6-15-19(9-16(11)26...</td>\n",
       "      <td>C25H17F2N3O5</td>\n",
       "      <td>C 25 H 17 F 2 N 3 O 5 /c 1 - 11 - 6 - 15 - 19 ...</td>\n",
       "      <td>129</td>\n",
       "      <td>input/train/0/a/8/0a8f483e026a.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0a8f92df487d</td>\n",
       "      <td>InChI=1S/C20H25N3O/c1-3-18-14-22(2)19-7-5-4-6-...</td>\n",
       "      <td>C20H25N3O</td>\n",
       "      <td>C 20 H 25 N 3 O /c 1 - 3 - 18 - 14 - 22 ( 2 ) ...</td>\n",
       "      <td>91</td>\n",
       "      <td>input/train/0/a/8/0a8f92df487d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0a8f9b6a138f</td>\n",
       "      <td>InChI=1S/C21H21ClN2O4S/c1-4-24(19-11-7-9-15-8-...</td>\n",
       "      <td>C21H21ClN2O4S</td>\n",
       "      <td>C 21 H 21 Cl N 2 O 4 S /c 1 - 4 - 24 ( 19 - 11...</td>\n",
       "      <td>89</td>\n",
       "      <td>input/train/0/a/8/0a8f9b6a138f.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0a8fadf04db1</td>\n",
       "      <td>InChI=1S/C17H24N2O2/c1-12-8-6-7-11-15(12)19-16...</td>\n",
       "      <td>C17H24N2O2</td>\n",
       "      <td>C 17 H 24 N 2 O 2 /c 1 - 12 - 8 - 6 - 7 - 11 -...</td>\n",
       "      <td>98</td>\n",
       "      <td>input/train/0/a/8/0a8fadf04db1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0a8fb2c73338</td>\n",
       "      <td>InChI=1S/C23H30BrN3O4S2/c1-4-13-27(14-5-2)33(2...</td>\n",
       "      <td>C23H30BrN3O4S2</td>\n",
       "      <td>C 23 H 30 Br N 3 O 4 S 2 /c 1 - 4 - 13 - 27 ( ...</td>\n",
       "      <td>117</td>\n",
       "      <td>input/train/0/a/8/0a8fb2c73338.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id                                              InChI  \\\n",
       "0      000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "1      000045d5fbf9  InChI=1S/C13H15BrN2O3/c1-7-5-15-6-9(7)12(17)16...   \n",
       "2      0000642345c8  InChI=1S/C16H12O7/c1-22-14-5-9(18)8(4-10(14)19...   \n",
       "3      000092011e0d  InChI=1S/C13H14O2/c14-12-8-9-13(15)11(12)7-6-1...   \n",
       "4      0000960e9456  InChI=1S/C9H7BrClN3S/c10-7-3-1-6(2-4-7)5-12-9-...   \n",
       "...             ...                                                ...   \n",
       "19995  0a8f483e026a  InChI=1S/C25H17F2N3O5/c1-11-6-15-19(9-16(11)26...   \n",
       "19996  0a8f92df487d  InChI=1S/C20H25N3O/c1-3-18-14-22(2)19-7-5-4-6-...   \n",
       "19997  0a8f9b6a138f  InChI=1S/C21H21ClN2O4S/c1-4-24(19-11-7-9-15-8-...   \n",
       "19998  0a8fadf04db1  InChI=1S/C17H24N2O2/c1-12-8-6-7-11-15(12)19-16...   \n",
       "19999  0a8fb2c73338  InChI=1S/C23H30BrN3O4S2/c1-4-13-27(14-5-2)33(2...   \n",
       "\n",
       "              InChI_1                                         InChI_text  \\\n",
       "0         C10H19N3O2S  C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...   \n",
       "1        C13H15BrN2O3  C 13 H 15 Br N 2 O 3 /c 1 - 7 - 5 - 15 - 6 - 9...   \n",
       "2            C16H12O7  C 16 H 12 O 7 /c 1 - 22 - 14 - 5 - 9 ( 18 ) 8 ...   \n",
       "3            C13H14O2  C 13 H 14 O 2 /c 14 - 12 - 8 - 9 - 13 ( 15 ) 1...   \n",
       "4         C9H7BrClN3S  C 9 H 7 Br Cl N 3 S /c 10 - 7 - 3 - 1 - 6 ( 2 ...   \n",
       "...               ...                                                ...   \n",
       "19995    C25H17F2N3O5  C 25 H 17 F 2 N 3 O 5 /c 1 - 11 - 6 - 15 - 19 ...   \n",
       "19996       C20H25N3O  C 20 H 25 N 3 O /c 1 - 3 - 18 - 14 - 22 ( 2 ) ...   \n",
       "19997   C21H21ClN2O4S  C 21 H 21 Cl N 2 O 4 S /c 1 - 4 - 24 ( 19 - 11...   \n",
       "19998      C17H24N2O2  C 17 H 24 N 2 O 2 /c 1 - 12 - 8 - 6 - 7 - 11 -...   \n",
       "19999  C23H30BrN3O4S2  C 23 H 30 Br N 3 O 4 S 2 /c 1 - 4 - 13 - 27 ( ...   \n",
       "\n",
       "       InChI_length                           file_path  fold  \n",
       "0                72  input/train/0/0/0/000026fc6c36.png     0  \n",
       "1                97  input/train/0/0/0/000045d5fbf9.png     0  \n",
       "2                84  input/train/0/0/0/0000642345c8.png     0  \n",
       "3                53  input/train/0/0/0/000092011e0d.png     0  \n",
       "4                60  input/train/0/0/0/0000960e9456.png     0  \n",
       "...             ...                                 ...   ...  \n",
       "19995           129  input/train/0/a/8/0a8f483e026a.png     0  \n",
       "19996            91  input/train/0/a/8/0a8f92df487d.png     0  \n",
       "19997            89  input/train/0/a/8/0a8f9b6a138f.png     0  \n",
       "19998            98  input/train/0/a/8/0a8fadf04db1.png     0  \n",
       "19999           117  input/train/0/a/8/0a8fb2c73338.png     0  \n",
       "\n",
       "[20000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating encoder ..\n",
      "Creating decoder ..\n",
      "Starting loop ..\n",
      "Epoch: 0\n",
      "Starting training ..\n",
      "Switching to train mode ..\n",
      "Enumerating train loader ..\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
